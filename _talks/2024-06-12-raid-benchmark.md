---
title: "RAID: A Shared Benchmark for Robust Evaluation of Machine-Generated Text Detectors"
collection: talks
type: "Invited Talk"
permalink: /talks/2024-06-12-raid-benchmark
venue: "University of Maryland"
date: 2024-06-12
location: "College Park, Maryland"
---

<iframe src="https://docs.google.com/presentation/d/e/2PACX-1vSJswIJcJMNyvwGcYeCuDZ2gRpVyEvUzuCEKFLHeS3WOh2AGd3ORrEBeLECBsPseOOR7dnGnjxgCjw4/embed?start=false&loop=false&delayms=3000" frameborder="0" width="560" height="315" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>

-------
### Abstract
In this short five-minute talk I introduce RAID: the largest and most challenging benchmark dataset for generated text detection. I discuss two key findings from the paper, namely that all detectors when calibrated to FPR=1% achieve accuracies of less than 50% and that many detectors are extremely suscetible to low edit-distance adversarial attacks such as whitespace insertion and article deletion.

### Location
This talk was given on June 12th 2024 at the University of Maryland in College Park, Maryland as part of the IARPA HIATUS program.

### Links
[Slides](https://docs.google.com/presentation/d/1yRqfSsS1KnTu8KRWOtvFQmcPBSVtsax4WrglKui2fX8/edit?usp=sharing), [Paper](https://arxiv.org/abs/2405.07940), [Code](https://github.com/liamdugan/raid)